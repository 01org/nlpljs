Content Push
============

Content-Push (CP) is a design concept for the web. The basic idea is to use the
content on the current tab and aggreate content from other parts of the net,
truested sources, related to the current context. The PoC is being developed with
Google Docs. The document text is parsed and analysed to extract the keywords, a
search is made using these keywords and the results are displayed in a panel.

CP is implemented as a chrome extension(page action) and can be downloaded
from github: https://github.com/otcshare/ContentPush.
CP uses google polymer framework for implementation. All the dependencies can be
installed by running a 'bower install' command in the root directory.
Add the app/ dir as a unpacked extentsion.

This document is inteded for anyone who wishes to contribute to the project, it
dicusses the implementation details and design on the app to get you up and running.
This document is work in progress.

Overview of app structure
=========================

The app is composed of multiple parts that exist in three(and a half) different contexts :

1. The extension - event_page.js
   the 'main' of the entire app
   all(?) chrome apis can be used here

2. The web worker - nlp_worker.js
   this is where the nlp work is done
   no chrome apis can be used here

3. The web app - cp-main.html
   this is where the user interaction is done and is the majority of the functionality
   of the app
   very few chrome apis can be used here, but if those apis aren't needed for a
   particular piece of functionality, then this is where it goes
   
3.5 The content script - rehostPage.js
   this lives in what is termed as an 'isolated world'. It's in the web app context,
   but severely limited access to the web app itself, pretty much only the DOM itself.
   
The extension :

1. executes the content script inside the web app,
2. starts the web worker
3. performs tasks that require chrome apis only available in this context
4. message passing related to the above

The web worker is dedicated to nlp processing.

The content script does 'editing' of the web app, and some message passing.

Detail of wep app context
=========================

CP relies heavily on Google Polymer. Everything is split into custom components.
When CP is launched, the event page records the tab URL. It throws away the current
DOM tree. It reloads the tab URL in an iframe inside a component {<cp-document>}.
It also loads a separate component called <cp-finder> which is responsible for
aggregating data about the contents of the URL. The <core-splitter> is used to
keep a fluid boundry between <cp-document> and <cp-finder>.
app/script/rehostPage.js is the content script which injects these components in
the current tab. app/script/event_page.js is the background-page.

	    |----> <cp-document>
	    |
tab URL ----|-<core-splitter>
	    |
	    |----> <cp-finder>

<cp-document> component
=======================
<cp-document> loads the tab URL contents. The reason for re-loading the URL in a
separate component is to keep its content processing separate from the rest of the
extension. The other advantage of a separate component is the element can be tailored
to the type of content served by the URL (e.g google doc vs Netflix).
<cp-document> is made up of various modules. An internal 'state; is maintained to
keep all the elements in sync.

Methods:<tbd>
Signals:
1. cp-status:	Emits the current status of the component.
   		The status values are still <tbd>.
2. cp-keywords: Emits the keywords in the current viewport.

<cp-document>
      |
      |--> iframe
      |
      |--> NLP
      |
      |--> <cp-keyword-highlighter>
      |
      |--> <cp-scrollwatcher>

The iframe loads the tab url.
The NLP module processes the text from the displayed content and extracts the
'keywords' from it.

<cp-keyword-highlighter>
========================
This is a custom element, which is responsible for highlighting specific contents inside the iframe.

Methods:<tbd>
signals:<tbd>

<cp-scrollwatcher>
==================
This is a custom element which watches the window scroll events. Once the scroll stops,
<cp-scrollwatcher> computes the visible content in the iframe.

Methods:<tbd>
signals:<tbd>


<cp-finder>
===========
<cp-finder> is a custom element which is responsible for searching content for
the keywords from <cp-document>, result layouts and sources selection UI.

Methods:<tbd>
signals:<tbd>

<cp-finder> is a collection of the following components.

<cp-finder>
     |
     |--<cp-groups>
     |
     |--<cp-sources>
     |
     |--<cp-panel>
     |      |
     |      |--<cp-tabs>
     |      |
     |      |--<cp-display>
     |             |
     |             |--<cp-layout>
     |             |      |
     |             |      |--<cp-tile*>
     |             |
     |             |--<cp-scroll>
     |
     |--<cp-aggregator>
     |
     |--<cp-fetcher>
     |
     |--<cp-detail>

<cp-tabs>
=========
This is a custom element for displaying the the source groups.
Refer UX Doc page 38.

Methods:<tbd>
signals:<tbd>

<cp-groups>
===========
This is the custom element for selecting the source groups.
Refer UX Doc page 38.

Methods:<tbd>
signals:<tbd>

<cp-sources>
============
This is a custom element for selecting the sources in a group.
Refer UX Doc page 38.

Methods:<tbd>
signals:<tbd>

<cp-panel>
============
This is a custome element which encapuslates <cp-tabs> and <cp-display>.
This element is replaced by <cp-sources> or <cp-group> which configuring
the groups/sources.

Methods:<tbd>
signals:<tbd>

<cp-display>
============
This is a custom element to display the results from search.

Methods:<tbd>
signals:<tbd>

<cp-layout>
===========
This is a custom element which implements the gallery layout.

Methods:<tbd>
signals:<tbd>

<cp-tile*>
==========
This is a base element which represents a given search result.
Depending on the result type, a new element can be extended -
<cp-tile-image>, <cp-tile-quote>,  <cp-tile-doc> etc.

Methods:<tbd>
signals:<tbd>

<cp-scroll>
===========
This is a custom element which takes care of the scrolling (and adding more
elements) in the layout element.

Methods:<tbd>
signals:<tbd>

<cp-aggregator>
===============
This is a custom element which aggregates all the results from the sources
web-workers.

Methods:<tbd>
signals:<tbd>

<cp-fetcher>
============
This is a custom element which spawns a web-worker per sources per keyword.

Methods:<tbd>
signals:<tbd>

<cp-detail>
============
This is a custom element which displays the details about a <cp-tile>

Methods:<tbd>
signals:<tbd>

EXIF data
=========

As part of determining what's possible with images in Content Push,
I did some experiments with extracting EXIF data from image files.
The library I used for this was exif-js (https://github.com/jseidelin/exif-js).

exif-js requires a Blob representing the image to be available. To
get this, the image has to be fetched via Ajax. (See below for my
experiments in doing this without Ajax.) The image can then be
pushed through exif-js to extract its metadata.

I figured out a way to do this using an unmodified version of exif-js,
both from local (file://) and remote (http://) files. However, there
is one big drawback: When loading a remote image, the server hosting
the image must be enabled for CORS (http://enable-cors.org/). If not,
you will see "Access origin not allowed" messages in the console when
the app tried to load the image, and it will not be accessible via Ajax.

Here's the code which will download and parse an image using exif-js,
either from a local or remote (on a CORS-enabled server) image:

  var fetchImage = function (imageUrl, cb) {
    var http = new XMLHttpRequest();
    http.open('GET', imageUrl, true);
    http.responseType = 'blob';

    http.onload = function () {
      if (this.readyState === 4 && this.status < 400) {
        var image = new Image();

        image.onload = function () {
          EXIF.getData(image, function () {
            // EXIF data is available as "this"
            cb(this);
          });
        };

        var blobUrl = URL.createObjectURL(this.response);
        image.src = blobUrl;
      }
      else {
        console.error('Error fetching image');
      }
    };

    http.send();
  };

NB there is some redundancy here, as exif-js will fire up another
XMLHttpRequest to fetch the image in binary format before parsing it.
(I came up with a patch which will avoid this, but I'm not sure whether
the exif-js maintainer will want to merge it.)

I experimented with loading a remote image into an Image object, then
tried to get the binary data from it. The de facto standard way to do
this is to write the image into a canvas; then get a data URL
representing the content of the canvas (via canvas.getDataURL());
then manipulate that Base64-encoded representation into a Blob. However,
my experiments showed that this loses the EXIF data at the point where
the canvas' data URL is retrieved. For that reason, while it works,
it is not feasible, as the EXIF data is what we're after.
